#include "cl_viv_vx_ext.h"

/********************************************L2NormalizeScale*****************************************/
_viv_uniform int L2NorS_depth;
_viv_uniform VXC_512Bits UniFp16MulLo_dp4x4;
_viv_uniform VXC_512Bits UniFp16MulHi_dp4x4;
__kernel void vxcL2NormScale_SumRsqrt
    (
    image2d_array_t input,
    image2d_array_t output,
    int dim
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), 0);
    vxc_short8 img1_s16, img2_s16;
    vxc_float4 squr, sum_lo = 0, sum_hi = 0;
    vxc_half8 img1_fp16, img2_fp16;
    half4 val1_h, val2_h;
    for(int i = 0; i < L2NorS_depth; i += 2)
    {
        VXC_ReadImage(img1_s16, input, coord.xy, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        VXC_ReadImage(img2_s16, input, coord.xy, VXC_5BITOFFSET_XY(0, 1),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        coord.y += 2;
        _viv_asm(COPY, img1_fp16, img1_s16, 16);
        _viv_asm(COPY, img2_fp16, img2_s16, 16);
        _viv_asm(COPY, img1_fp16, img1_s16, 16);
        _viv_asm(COPY, img2_fp16, img2_s16, 16);

        VXC_DP4x4(squr, img1_fp16, img1_fp16, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 1),\
            UniFp16MulLo_dp4x4);
        sum_lo += squr;
        VXC_DP4x4(squr, img2_fp16, img2_fp16, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 1),\
            UniFp16MulLo_dp4x4);
        sum_lo += squr;
        VXC_DP4x4(squr, img1_fp16, img1_fp16, VXC_MODIFIER(0, 3, 4, VXC_RM_TowardZero, 1),\
            UniFp16MulHi_dp4x4);
        sum_hi += squr;
        VXC_DP4x4(squr, img2_fp16, img2_fp16, VXC_MODIFIER(0, 3, 4, VXC_RM_TowardZero, 1),\
            UniFp16MulHi_dp4x4);
        sum_hi += squr;
    }
    sum_lo = rsqrt(sum_lo);
    sum_hi = rsqrt(sum_hi);
    write_imagef(output, coord.zwww, sum_lo);
    coord.z += 4;
    write_imagef(output, coord.zwww, sum_hi);
}
//int8 version
_viv_uniform float r_inputScale;
_viv_uniform VXC_512Bits uniIntegerSquareLo_4x4;
_viv_uniform VXC_512Bits uniIntegerSquareHi_4x4;
_viv_uniform VXC_512Bits uniDataSquareAddU32Lo_4x4;
_viv_uniform VXC_512Bits uniDataSquareAddU32Hi_4x4;
__kernel void vxcL2NormScale_SumRsqrt_int8
    (
    image2d_array_t input,
    image2d_array_t output,
    int dim
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), 0);
    vxc_char8 src0, src1;
    vxc_uint4 dst0 = 0, dst1 = 0;
    for(int i = 0; i < L2NorS_depth; i += 2)
    {
        VXC_ReadImage(src0, input, coord.xy, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        VXC_ReadImage(src1, input, coord.xy, VXC_5BITOFFSET_XY(0, 1),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        coord.y += 2;
        VXC_DP4x4(dst0, src0, dst0, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniDataSquareAddU32Lo_4x4);
        VXC_DP4x4(dst1, src0, dst1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniDataSquareAddU32Hi_4x4);
        VXC_DP4x4(dst0, src1, dst0, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniDataSquareAddU32Lo_4x4);
        VXC_DP4x4(dst1, src1, dst1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniDataSquareAddU32Hi_4x4);
    }
    vxc_float4 sum_lo, sum_hi;
    sum_lo = convert_float4(dst0);
    sum_hi = convert_float4(dst1);
    sum_lo = rsqrt(sum_lo) * r_inputScale;
    sum_hi = rsqrt(sum_hi) * r_inputScale;
    write_imagef(output, coord.zwww, sum_lo);
    coord.z += 4;
    write_imagef(output, coord.zwww, sum_hi);
}
__kernel void vxcL2NormScale_SumRsqrt_int16
    (
    image2d_array_t input,
    image2d_array_t output,
    int dim
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), 0);
    vxc_short8 src0, src1;
    vxc_float4 squr, sum_lo = 0, sum_hi = 0;
    for(int i = 0; i < L2NorS_depth; i += 2)
    {
        VXC_ReadImage(src0, input, coord.xy, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        VXC_ReadImage(src1, input, coord.xy, VXC_5BITOFFSET_XY(0, 1),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        coord.y += 2;
        VXC_DP4x4(squr, src0, src0, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniIntegerSquareLo_4x4);
        sum_lo = squr + sum_lo;
        VXC_DP4x4(squr, src0, src0, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniIntegerSquareHi_4x4);
        sum_hi = squr + sum_hi;
        VXC_DP4x4(squr, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniIntegerSquareLo_4x4);
        sum_lo = squr + sum_lo;
        VXC_DP4x4(squr, src1, src1, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0),\
            uniIntegerSquareHi_4x4);
        sum_hi = squr + sum_hi;
    }
    sum_lo = rsqrt(sum_lo) * r_inputScale;
    sum_hi = rsqrt(sum_hi) * r_inputScale;
    write_imagef(output, coord.zwww, sum_lo);
    coord.z += 4;
    write_imagef(output, coord.zwww, sum_hi);
}
_viv_uniform VXC_512Bits uniUInt8SquareLo_4x4;
_viv_uniform VXC_512Bits uniUInt8SquareHi_4x4;
_viv_uniform int inputZP;
__kernel void vxcL2NormScale_SumRsqrt_uint8
    (
    image2d_array_t input,
    image2d_array_t output,
    int dim
    )
{
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), 0);
    vxc_uchar8 src0, src1;
    vxc_float4 squr, sum_lo = 0, sum_hi = 0;
    for(int i = 0; i < L2NorS_depth; i += 2)
    {
        vxc_uchar8 zero;
        VXC_ReadImage(src0, input, coord.xy, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        VXC_ReadImage(src1, input, coord.xy, VXC_5BITOFFSET_XY(0, 1),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));
        coord.y += 2;
        _viv_asm(COPY, zero, inputZP, 4);
        VXC_DP4x4(squr, src0, zero, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniUInt8SquareLo_4x4);
        sum_lo = squr + sum_lo;
        VXC_DP4x4(squr, src0, zero, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniUInt8SquareHi_4x4);
        sum_hi = squr + sum_hi;
        VXC_DP4x4(squr, src1, zero, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniUInt8SquareLo_4x4);
        sum_lo = squr + sum_lo;
        VXC_DP4x4(squr, src1, zero, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardZero, 0), uniUInt8SquareHi_4x4);
        sum_hi = squr + sum_hi;
    }
    sum_lo = rsqrt(sum_lo) * r_inputScale;
    sum_hi = rsqrt(sum_hi) * r_inputScale;
    write_imagef(output, coord.zwww, sum_lo);
    coord.z += 4;
    write_imagef(output, coord.zwww, sum_hi);
}

/****************************L2NormalizeMulScale**********************************/

_viv_uniform VXC_512Bits uniDataSubZPtoFp32Part0_4x4;
_viv_uniform VXC_512Bits uniDataSubZPtoFp32Part1_4x4;
_viv_uniform VXC_512Bits uniExtact8Bin_2x8;
_viv_uniform VXC_512Bits uniFp16toFp32_4x4;
_viv_uniform float IntergerScale;
_viv_uniform float output_ZP;
#define L2NORMSCALE_MIXED_MODE(name0, name1, input_type, incopy_type,\
    output_type, convert_type, copy_type) \
    __kernel void vxcL2NormScale_##name0##to##name1\
    (\
    __read_only  image2d_array_t input1,\
    __read_only  image2d_array_t input2,\
    __read_only  image2d_array_t scale,\
    __write_only image2d_array_t output,\
    int dim\
    )\
{\
    int4 coord = (int4)(get_global_id(0), get_global_id(1), get_global_id(0), 0);\
    input_type  vect0, vect1;\
    incopy_type src0, src1;\
    vxc_float4 rsqrt0, rsqrt1;\
    rsqrt0 = read_imagef(input2, coord.zwww);\
    coord.z += 4;\
    rsqrt1 = read_imagef(input2, coord.zwww);\
    rsqrt0 *= IntergerScale;\
    rsqrt1 *= IntergerScale;\
    for(int i = 0; i < L2NorS_depth; i += 2)\
   {\
        vxc_float4 vec0, vec1;\
        input_type input_ZP ;\
        convert_type dst0, dst1;\
        VXC_ReadImage(vect0, input1, coord.xy, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));\
        _viv_asm(COPY, src0, vect0, 16); \
        VXC_ReadImage(vect1, input1, coord.xy, VXC_5BITOFFSET_XY(0, 1),\
            VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));\
        _viv_asm(COPY, src1, vect1, 16); \
        vxc_short8 scale_s16;\
        vxc_half8  scale_f16;\
        vxc_float4 scale_f32;\
        VXC_ReadImage(scale_s16, scale, coord.yw, VXC_5BITOFFSET_XY(0, 0),\
            VXC_MODIFIER(0, 1, 0, VXC_RM_TowardZero, 0));\
        _viv_asm(COPY, scale_f16, scale_s16, 16); \
        _viv_asm(COPY, input_ZP, inputZP, 4); \
        VXC_DP4x4(vec0, src0, input_ZP, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardInf, 0),\
            uniDataSubZPtoFp32Part0_4x4);\
        VXC_DP4x4(vec1, src0, input_ZP, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardInf, 0),\
            uniDataSubZPtoFp32Part1_4x4);\
        VXC_DP4x4(scale_f32, scale_f16, scale_f16, VXC_MODIFIER(0, 1, 0, VXC_RM_TowardInf, 0),\
            uniFp16toFp32_4x4);\
        vec0 = vec0 * rsqrt0 + output_ZP;\
        vec1 = vec1 * rsqrt1 + output_ZP;\
        vec0 *= scale_f32.xxxx;\
        vec1 *= scale_f32.xxxx;\
        _viv_asm(CONV_RTE, dst0, vec0);\
        _viv_asm(CONV_RTE, dst1, vec1);\
        output_type dst2;\
        VXC_DP2x8(dst2, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniExtact8Bin_2x8);\
        copy_type dst;\
        _viv_asm(COPY, dst, dst2, 16); \
        VXC_WriteImage(output, coord.xy, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));\
        VXC_DP4x4(vec0, src1, input_ZP, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardInf, 0),\
            uniDataSubZPtoFp32Part0_4x4);\
        VXC_DP4x4(vec1, src1, input_ZP, VXC_MODIFIER(0, 3, 0, VXC_RM_TowardInf, 0),\
            uniDataSubZPtoFp32Part1_4x4);\
        vec0 = vec0 * rsqrt0 + output_ZP;\
        vec1 = vec1 * rsqrt1 + output_ZP;\
        vec0 *= scale_f32.yyyy;\
        vec1 *= scale_f32.yyyy;\
        _viv_asm(CONV_RTE, dst0, vec0);\
        _viv_asm(CONV_RTE, dst1, vec1);\
        VXC_DP2x8(dst2, dst0, dst1, VXC_MODIFIER(0, 7, 0, VXC_RM_ToNearestEven, 1), uniExtact8Bin_2x8);\
        coord.y++;\
        _viv_asm(COPY, dst, dst2, 16); \
        VXC_WriteImage(output, coord.xy, dst, VXC_MODIFIER(0, 7, 0, VXC_RM_TowardZero, 0));\
        coord.y++;\
    }\
}
//                     name0, name1, input_type,  incopy_type, output_type, convert_type, copy_type
L2NORMSCALE_MIXED_MODE(Fp16,  Fp16,  vxc_short8,  vxc_half8,   vxc_half8,   half4,        vxc_short8)
L2NORMSCALE_MIXED_MODE(Int8,  Int8,  vxc_char16,  vxc_char16,  vxc_char16,  int4,         vxc_char16)
L2NORMSCALE_MIXED_MODE(Int8,  Fp16,  vxc_char16,  vxc_char16,  vxc_half8,   half4,        vxc_short8)
L2NORMSCALE_MIXED_MODE(UInt8, Fp16,  vxc_uchar16, vxc_uchar16, vxc_half8,   half4,        vxc_short8)
L2NORMSCALE_MIXED_MODE(UInt8, UInt8, vxc_uchar16, vxc_uchar16, vxc_uchar16, int4,         vxc_uchar16)
L2NORMSCALE_MIXED_MODE(Int16, Int16, vxc_short8,  vxc_short8,  vxc_short8,  int4,         vxc_short8)
L2NORMSCALE_MIXED_MODE(Int16, Fp16,  vxc_short8,  vxc_short8,  vxc_half8,   half4,        vxc_short8)
//L2NORMSCALE_MIXED_MODE(Fp16,  Int8,  vxc_short8,  vxc_half8,   vxc_char16,  int4,         vxc_char16)
//L2NORMSCALE_MIXED_MODE(Fp16,  UInt8, vxc_short8,  vxc_half8,   vxc_uchar16, int4,         vxc_uchar16)
//L2NORMSCALE_MIXED_MODE(Fp16,  Int16, vxc_short8,  vxc_half8,   vxc_short8,  int4,         vxc_short8)
